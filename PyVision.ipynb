{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "name": "PyVision.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "interpreter": {
      "hash": "cb107d135c90e19954bbeef92810089d243cf8f250a28954a8682a1aa176086a"
    },
    "kernelspec": {
      "display_name": "Python 3.8.8 64-bit ('JupyterLab': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqdhiOwRUsxS"
      },
      "source": [
        "# Lab 8 - PyVision"
      ],
      "id": "uqdhiOwRUsxS"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Vo_qkPfUsxT"
      },
      "source": [
        "The purpose of this lab is to help you become more familiar with:\n",
        "* Exploratory Computing\n",
        "* Python\n",
        "* Jupyter notebooks\n",
        "* The tiniest bit of Linux"
      ],
      "id": "-Vo_qkPfUsxT"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EezkEpOgUsxT"
      },
      "source": [
        "What to do:\n",
        "\n",
        "Execute each of the cells in turn.  Do not skip any cells!\n",
        "\n",
        "Everytime you execute a cell, you're changing the variable and function definitions change in the kernel, the brains of Python.  This lab is written such that if the cells above are correct and have been executed, the Python kernel should have what it needs to make the next cell work.\n",
        "\n",
        "However, along the way, you will find cells which must be corrected in order to get everything to work properly!  These will be indicated with `PROBLEM` at the top and `FIXME` on the specific lines which require your attention."
      ],
      "id": "EezkEpOgUsxT"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2l03m_8eUsxM"
      },
      "source": [
        "## Imports"
      ],
      "id": "2l03m_8eUsxM"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0MZtX10Pw-u9"
      },
      "source": [
        "Let's start by executing the import cells below."
      ],
      "id": "0MZtX10Pw-u9"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VGVvyMfUsxQ"
      },
      "source": [
        "from time import sleep, time\n",
        "from math import sin, cos, pi\n",
        "import numpy as np\n",
        "from scipy.ndimage.measurements import center_of_mass\n",
        "from PIL import Image, ImageDraw\n",
        "from IPython.display import clear_output, display"
      ],
      "id": "2VGVvyMfUsxQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36SZGJdUw-u_"
      },
      "source": [
        "Additionally, we'll also need to modules for interacting with the hardware.  Let's load them as well if you are executing this code on the Raspberry Pi.  Otherwise you can skip them."
      ],
      "id": "36SZGJdUw-u_"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEMpQ0TzUsxS"
      },
      "source": [
        "from picamera import PiCamera\n",
        "from adafruit_servokit import ServoKit"
      ],
      "id": "rEMpQ0TzUsxS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVsbHtAXw-vC"
      },
      "source": [
        "The function below just helps convert a Numpy array into an image on the screen.  You need to execute the cell, but don't worry about how it works."
      ],
      "id": "nVsbHtAXw-vC"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iitsGy2Uw-vE"
      },
      "source": [
        "def displayArray(npArray, verbose=False):\n",
        "    nDim = npArray.ndim\n",
        "    dtype = npArray.dtype\n",
        "    if verbose: print(\"nDim:\",nDim,\" dtype:\", dtype)\n",
        "    if(nDim == 3 and dtype == np.uint8):\n",
        "        (ny, nx, nc) = npArray.shape\n",
        "        if nc != 3:\n",
        "            print(\"8bit arrays with depth of 3 are expected to have three color channels\")\n",
        "            return\n",
        "        else:\n",
        "            display(Image.fromarray(npArray))\n",
        "    elif(nDim == 2 and dtype == np.float_):\n",
        "        if(np.min(npArray) < 0 or np.max(npArray > 1)):\n",
        "            print(\"float array is not in range [0,1]\")\n",
        "            return\n",
        "        else:\n",
        "            lum8Bit = np.clip(256*npArray, 0, 255).astype('uint8')  # Rescales the image data to 'uint8' in range [0, 255]\n",
        "            lum8BitRGB = np.dstack((lum8Bit, lum8Bit, lum8Bit))      # Turn it into RGB image.  The function np.dstack combines three 2D mxn arrays into one mxnx3 array.\n",
        "            display(Image.fromarray(lum8BitRGB))"
      ],
      "id": "iitsGy2Uw-vE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-gNAIJVUsxU"
      },
      "source": [
        "## Image Processing"
      ],
      "id": "1-gNAIJVUsxU"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-IFJ_LsWw-vG"
      },
      "source": [
        "### Images as Arrays"
      ],
      "id": "-IFJ_LsWw-vG"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EA8RYoK5UsxU"
      },
      "source": [
        "Computer images can come in a variety of formats, but the most common is that of a dense Red Green Blue (RGB) Array.  For an image which is $n+1$ pixels wide and $m+1$ pixels tall, this would look something like:\n",
        "```\n",
        "[[[r00, g00, b00], [r01, g01, b01], ... , [r0n, g0n, b0n]],\n",
        " [[r10, g10, b10], [r11, g11, b11], ... , [r1n, g1n, b1n]],\n",
        " ...\n",
        " [[rm0, gm0, bm0], [rm1, gm1, bm1], ... , [rmn, gmn, bmn]]]\n",
        " ```\n",
        " "
      ],
      "id": "EA8RYoK5UsxU"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XR-OX5JWUsxU"
      },
      "source": [
        "Note that the $(0, 0)$ pixel is in the upper-left hand corner.  The pixels fill in the same way you would write words on the page: left-to-right, top-to-bottom.  Similar to matrices, we describe the size of such a matrix by starting at the outside and working our way in.  The size of the above array would be `(m+1, n+1, 3)`.  In other words, it is `m+1` pixels tall, `n+1` pixels wide, and has `3` color components.\n",
        "\n",
        "Additionally, most computer monitors operate in 8-bit scale, meaning that the red value of a pixel can one of 256 values ranging from fully off (0) to fully on (255).  Why 256?  Because $2^8 = 256$."
      ],
      "id": "XR-OX5JWUsxU"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vALGNDDew-vJ"
      },
      "source": [
        "A common strategy before dealing with messy real-world data, is to begin with simple well-understood data.  Before capturing and processing images from a camera, we're going to make our own."
      ],
      "id": "vALGNDDew-vJ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvym7FMyUsxV"
      },
      "source": [
        "Let us begin by creating an array of zeros representing an image which is {H,W} = {150, 200}."
      ],
      "id": "mvym7FMyUsxV"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbDH3apHUsxV"
      },
      "source": [
        "testImageData = np.zeros(shape=(150, 200, 3), dtype=np.uint8)"
      ],
      "id": "jbDH3apHUsxV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wOaFY2UUsxV"
      },
      "source": [
        "We can visualize this data by converting it into an Image object."
      ],
      "id": "0wOaFY2UUsxV"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-Bo7zQfUsxW"
      },
      "source": [
        "displayArray(testImageData)"
      ],
      "id": "z-Bo7zQfUsxW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBLqeuspUsxW"
      },
      "source": [
        "We can use our Numpy indexing skills to alter this image.  For instance, let's put a red box in the middle.  \n",
        "\n",
        "As a referesher, the snippet of code below can be interpretted as \"for rows in the range [55, 95) and columns in the range [80, 120), change the RGB color value to [255, 0, 0]."
      ],
      "id": "iBLqeuspUsxW"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yy48J0pmUsxW"
      },
      "source": [
        "testImageData[55:95, 80:120] = [255, 0, 0]\n",
        "displayArray(testImageData)"
      ],
      "id": "Yy48J0pmUsxW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2OZfjxIUsxW"
      },
      "source": [
        "Ok... your turn!\n",
        "\n",
        "* Put a blue box in the upper-left hand corner\n",
        "* Put a green box in the lower-right hand corner\n",
        "* Put a white box in the upper-right hand corner"
      ],
      "id": "r2OZfjxIUsxW"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "El4l0YZMUsxX"
      },
      "source": [
        "# Problem\n",
        "testImageData = np.zeros(shape=(150, 200, 3), dtype=np.uint8)\n",
        "testImageData[:, :] = [0, 40, 0]                   # Make the image black  FIXME\n",
        "testImageData[20:40, 0:200] = [0, 0, 255]          # Blue box in upper-left corner FIXME\n",
        "testImageData[130:150, 0:200] = [0, 255, 0]        # Green box in lower-right corner FIXME\n",
        "testImageData[0:150, 180:200] = [255, 255, 255]    # White box in the upper-right corner FIXME\n",
        "displayArray(testImageData)                        # Let's look at it."
      ],
      "id": "El4l0YZMUsxX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tqm_ziX_w-vQ"
      },
      "source": [
        "The function below takes a numpy array and draws a circle of a given color and radius.  It returns a new array."
      ],
      "id": "tqm_ziX_w-vQ"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXTh95Gsw-vQ"
      },
      "source": [
        "def colorCircle(imageData, rcCenter, rad, color):\n",
        "    (nR, nC, _) = imageData.shape\n",
        "    imageDataNew = imageData.copy()\n",
        "    rCent, cCent = rcCenter\n",
        "    for c in range(nC):                                                   # Loop over all columns\n",
        "        for r in range(nR):                                               #   Loop over all rows\n",
        "            if (r-rCent)**2 + (c-cCent)**2 < rad**2:                      #     If pixel is in circle\n",
        "                imageDataNew[r, c] = color                                #       Set that pixel value to red.\n",
        "    return imageDataNew\n"
      ],
      "id": "IXTh95Gsw-vQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVzIpQd8w-vR"
      },
      "source": [
        "We're going to use it to add a red (`[255, 0, 0]`) circle centered on `(85, 110)`.  "
      ],
      "id": "OVzIpQd8w-vR"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JeWZwQBvw-vR"
      },
      "source": [
        "testImageDataDisk = colorCircle(testImageData, (85, 110), 20, [255, 0, 0])\n",
        "displayArray(testImageDataDisk)"
      ],
      "id": "JeWZwQBvw-vR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRn_u6yCw-vS"
      },
      "source": [
        "### Color Distance Computation"
      ],
      "id": "cRn_u6yCw-vS"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcHNuKglUsxX"
      },
      "source": [
        "Let's see if we can look for only the red objects in the image.  We're going to do this by dividing the image up into three color channels (red, green, blue) and then calculating a color distance for each pixel.  We'll borrow the typical distance formula from geometry $d = \\sqrt{((x_e - x_s)^2 + (y_e - y_s)^2 + (z_e - z_s)^2}$, but in this case, we'll use the colors as coordinates."
      ],
      "id": "hcHNuKglUsxX"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7iHSHNxoUsxX"
      },
      "source": [
        "# PROBLEM\n",
        "def computeColorDistance(rgbImageData, rgbTargetColor):\n",
        "    rVal, gVal, bVal = rgbTargetColor                               # break the target color up into it's red, green, and blue values\n",
        "    rCh = rgbImageData[:,:,0].astype('float')                       # separate the red channel from the image. (m,n) of 'float'.\n",
        "    gCh = rgbImageData[:,:,1].astype('float')                       #              green\n",
        "    bCh = rgbImageData[:,:,2].astype('float')                       #              blue\n",
        "    rDisp = (rCh - rVal)/255.                                       # compute the \"red displacement\" and normalize to one.  (m,n) of 'float' in range [0, 1]\n",
        "    gDisp = (gCh - gVal)/255.                                       #             \"green displacement\"\n",
        "    bDisp = (bCh - bVal)/255.                                       #             \"blue displacement\"\n",
        "    maxDist = ((1**2 + 1**2 + 1**2)**0.5)                           # The maximum possible distance assuming all three colors are 100% wrong\n",
        "    colorDist = ((rDisp**2 + gDisp + bDisp**2)**0.5) / maxDist      # Compute the normalized distance.  (m, n) 'float' in range [0, 1]  FIXME\n",
        "    return colorDist"
      ],
      "id": "7iHSHNxoUsxX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewt0N6FdUsxY"
      },
      "source": [
        "Code will often incorporate the idea of Unit Testing.  In Unit Testing, you test the code a small piece (typically a function) of the code for a handful of inputs/outputs that you can calculate and intuitively understand.  If enough of these simple tests behave as expected, then the unit (ie function) will likely also behave as expected.  If all of the functions behave as expected, then the code as a whole will behave as expected.\n",
        "\n",
        "In traditional programming, these tests are often relegated to other files with complex automatic test runners.  However, in exploratory computing, it's nice to keep things simple just put them near the code it's testing.  This way you can use them for debugging.  Some people will actually write the tests first!\n",
        "\n",
        "Let's check our color distance finder for several single pixel images."
      ],
      "id": "ewt0N6FdUsxY"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kwk0IwW5UsxY"
      },
      "source": [
        "whitePixel = np.array([255, 255, 255], 'uint8')\n",
        "redPixel = np.array([255, 0, 0], 'uint8')\n",
        "blackPixel = np.array([0, 0, 0], 'uint8')\n",
        "\n",
        "print(\"Black to White color -> 1.0\")\n",
        "testImageDataUT = np.array([[blackPixel]], 'uint8')\n",
        "dUT = computeColorDistance(testImageDataUT, whitePixel)\n",
        "print(\"  got:\", dUT)\n",
        "\n",
        "print(\"White to White -> 0.0\")\n",
        "testImageDataUT = np.array([[whitePixel]], 'uint8')\n",
        "dUT = computeColorDistance(testImageDataUT, whitePixel)\n",
        "print(\"  got:\", dUT)\n",
        "\n",
        "print(\"Red to Red -> 0.0\")\n",
        "testImageDataUT = np.array([[redPixel]], 'uint8')\n",
        "dUT = computeColorDistance(testImageDataUT, redPixel)\n",
        "print(\"  got:\", dUT)\n",
        "\n",
        "print(\"Red to Black -> 1/sqrt(3) = 0.577\")\n",
        "testImageDataUT = np.array([[redPixel]], 'uint8')\n",
        "dUT = computeColorDistance(testImageDataUT, blackPixel)\n",
        "print(\"  got:\", dUT)"
      ],
      "id": "Kwk0IwW5UsxY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zg4JI2BQw-vW"
      },
      "source": [
        "It's also good to test the code at a system level as we expect to use it.  Does the image make sense?"
      ],
      "id": "zg4JI2BQw-vW"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwLB9ZKiw-vW"
      },
      "source": [
        "red = np.array([255, 0, 0], 'uint8')\n",
        "distData = computeColorDistance(testImageDataDisk, red)\n",
        "displayArray(distData)"
      ],
      "id": "EwLB9ZKiw-vW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mg-EI23aw-vX"
      },
      "source": [
        "### Binarization"
      ],
      "id": "mg-EI23aw-vX"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1IP_2S-w-vX"
      },
      "source": [
        "We're going to want to \"binarize\" this distance data such that anything smaller than a certain \"threshold\" becomes one and anything greater becomes zero.  This is useful for creating an image \"mask\" for image processing which hightlights the regions where there distance error is considered small enough."
      ],
      "id": "B1IP_2S-w-vX"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ES29xV_LUsxZ"
      },
      "source": [
        "# PROBLEM\n",
        "def thresholdBinarize(distData, threshold):\n",
        "    maskData = np.where(distData < threshold, 0.3, 0.8) # FIXME\n",
        "    return maskData"
      ],
      "id": "ES29xV_LUsxZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jkCNmOwSw-vZ"
      },
      "source": [
        "And let's test this function to make sure it is working as expected."
      ],
      "id": "jkCNmOwSw-vZ"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Wp0Oef9Bw-vZ"
      },
      "source": [
        "print(\"Expected: [[1., 1., 0., 0., 0.]]\")\n",
        "testData = np.array([[0., 0.25, 0.5, 0.75, 1.0]])\n",
        "thresholdBinarize(testData, 0.4)"
      ],
      "id": "Wp0Oef9Bw-vZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxaXLLlQw-vZ"
      },
      "source": [
        "Let's combine the two functions to see if we can isolate the red disk.  \n",
        "\n",
        "In the code below, make sure we're searching for the correct color with tight\n",
        "enough threshold."
      ],
      "id": "nxaXLLlQw-vZ"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "d_6ty4Fnw-va"
      },
      "source": [
        "# PROBLEM \n",
        "red = np.array([0, 255, 0], 'uint8')                    # FIXME\n",
        "distData = computeColorDistance(testImageDataDisk, red)\n",
        "binData = thresholdBinarize(distData, 0.65)             # FIXME\n",
        "displayArray(binData)"
      ],
      "id": "d_6ty4Fnw-va",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88AtMxpRw-vb"
      },
      "source": [
        "### Dimming an Image Using a Mask"
      ],
      "id": "88AtMxpRw-vb"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3PyTyVPw-vb"
      },
      "source": [
        "We can do cool things by combing the mask with an image.  For instance, we can use the mask to dim all of the part of the image which are not selected.  Again, we do this by manipulating the arrays.\n",
        "\n",
        "We want scale factor function such that `SF(0) -> dimFactor` and `SF(1) -> 1`.  Then when we multiply this array by the image data, all of the unselected pixels (the zeros) will be driven to a maximum brightness of `dimFactor`.  By inspection, we see that `SF(m) = (m)*1 + (1 - m)*dimFactor` has these properties."
      ],
      "id": "d3PyTyVPw-vb"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "fP0XGBi2UsxZ"
      },
      "source": [
        "def imageDimmer(imageData, mask, dimFactor):\n",
        "    maskF = mask.astype('float')\n",
        "    scalingImageData = (1 - maskF)*dimFactor + maskF\n",
        "    dimmedImageData = (imageData * np.atleast_3d(scalingImageData)).astype('uint8')\n",
        "    return dimmedImageData"
      ],
      "id": "fP0XGBi2UsxZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "soxKr02pw-vc"
      },
      "source": [
        "As a quick test, consider two white pixels and a mask that \"selects\" the first one.  Note that the processed image dimmed the second pixel to about 25% of its original value."
      ],
      "id": "soxKr02pw-vc"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1k5AM6G9w-vc"
      },
      "source": [
        "whitePixel = np.array([255,255,255], \"uint8\")\n",
        "testData = np.array([[ whitePixel, whitePixel ]])\n",
        "mask = np.array([[1, 0]])\n",
        "imageDimmer(testData, mask, 0.25)"
      ],
      "id": "1k5AM6G9w-vc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNc4bKwvw-vc"
      },
      "source": [
        "Let's now add that in."
      ],
      "id": "ZNc4bKwvw-vc"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "hHPuofpdw-vd"
      },
      "source": [
        "red = np.array([255, 0, 0], 'uint8')\n",
        "distData = computeColorDistance(testImageDataDisk, red)\n",
        "maskData = thresholdBinarize(distData, 0.2)\n",
        "dimmedImage = imageDimmer(testImageDataDisk, maskData, 0.1)\n",
        "displayArray(dimmedImage)"
      ],
      "id": "hHPuofpdw-vd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O58iOT5Sw-vd"
      },
      "source": [
        "### Center-of-Mass Calcuation"
      ],
      "id": "O58iOT5Sw-vd"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gNYVXXpRw-vd"
      },
      "source": [
        "We're also going to need a method of determining the \"center of mass\" of a binary image.  We could implement our own, but the beauty of Python is the amount of existing libraries out there.  Let's use SciPy's `center_of_mass` function.  Consider the binary image below.  Does these results make sense?  Remember, that Python counts with zero-indexing."
      ],
      "id": "gNYVXXpRw-vd"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "C7QkmbNjUsxZ"
      },
      "source": [
        "testData = np.array([[0, 0, 1, 1, 1, 0, 0, 0, 0],\n",
        "                     [0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
        "center_of_mass(testData) # (row, column)"
      ],
      "id": "C7QkmbNjUsxZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4yX1M2bbw-ve"
      },
      "source": [
        "Alter the array in testData such that the center of mass is at `(0.5, 3.5)'"
      ],
      "id": "4yX1M2bbw-ve"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "NHOPlUNmw-ve"
      },
      "source": [
        "# PROBLEM\n",
        "testData = np.array([[0, 0, 1, 1, 1, 0, 0, 0, 0],   # FIXME\n",
        "                     [0, 0, 0, 0, 0, 0, 0, 0, 0]])  # FIXME\n",
        "center_of_mass(testData) # (row, column)"
      ],
      "id": "NHOPlUNmw-ve",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4pzrp9Cw-vf"
      },
      "source": [
        "Finally, let us now use `maskData`, which was `1` in the red circle and `0` \n",
        "elsewhere to determine the center of mass of the red circle.  Is this where we\n",
        "put it?"
      ],
      "id": "F4pzrp9Cw-vf"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "SrCiwTvMw-vg"
      },
      "source": [
        "red = np.array([255, 0, 0], 'uint8')\n",
        "distData = computeColorDistance(testImageDataDisk, red)\n",
        "maskData = thresholdBinarize(distData, 0.2)\n",
        "center_of_mass(maskData)"
      ],
      "id": "SrCiwTvMw-vg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SrwEVv6Kw-vh"
      },
      "source": [
        "### Combining Everything into a Function"
      ],
      "id": "SrwEVv6Kw-vh"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bz6IX3Obw-vh"
      },
      "source": [
        "Now that we've explored and tested each of the components, let's pull it all together.  This is called \"encapsulation.\"  It allows us to easily make use of the code.\n",
        "\n",
        "Copy and paste the appropriate lines above to build a function which:\n",
        "* finds an object in an image by color\n",
        "* computes where it is\n",
        "* displays a \"dimmed image\" that has the CoM highlighted by a green dot."
      ],
      "id": "Bz6IX3Obw-vh"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4knXPxbw-vi"
      },
      "source": [
        "# PROBLEM\n",
        "# def ImageTracker(testImageData, targetColor, threshold, dimFactor):\n",
        "#     distData = # FIXME\n",
        "#     maskData = # FIXME\n",
        "#     dimmedImage = # FIXME\n",
        "#     displayArray()# FIXME\n",
        "#     (rCoM, cCoM) = center_of_mass(maskData)\n",
        "#     return (rCoM, cCoM)"
      ],
      "id": "g4knXPxbw-vi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cE9y41oaw-vi"
      },
      "source": [
        "And let's test it on our image."
      ],
      "id": "cE9y41oaw-vi"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_wxMHF9w-vj"
      },
      "source": [
        "ImageTracker(testImageDataDisk, targetColor=[255, 0, 0], threshold=0.2, dimFactor=0.1)"
      ],
      "id": "W_wxMHF9w-vj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "av5lYdSMw-vj"
      },
      "source": [
        "Real-world data is messy.  How does this work on a actual photograph?"
      ],
      "id": "av5lYdSMw-vj"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bII9L9Na_eet"
      },
      "source": [
        "try:\n",
        "    baboonImg = Image.open('baboon.png')\n",
        "except:\n",
        "    try:\n",
        "        url = \"https://raw.githubusercontent.com/mikolalysenko/baboon-image/master/baboon.png\"\n",
        "        response = requests.get(url)\n",
        "        baboonImg = Image.open(BytesIO(response.content))\n",
        "    except:\n",
        "        print(\"No image loaded\")"
      ],
      "id": "bII9L9Na_eet",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0ST4lWgUsxa"
      },
      "source": [
        "baboonImageData = np.array(baboonImg)\n",
        "displayArray(baboonImageData)"
      ],
      "id": "D0ST4lWgUsxa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ygm4VofTw-vk"
      },
      "source": [
        "Adjust the settings below to find the center of the baboon's nose.  Because this is \"real world data,\" things won't be perfect, but it can be basically working."
      ],
      "id": "Ygm4VofTw-vk"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ip_gdq-Pw-vk"
      },
      "source": [
        "# PROBLEM\n",
        "ImageTracker(baboonImageData, targetColor=[100, 100, 255], threshold=0.25, dimFactor=0.1) # FIXME"
      ],
      "id": "Ip_gdq-Pw-vk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ii8lQkPJUsxb"
      },
      "source": [
        "# Image Capture"
      ],
      "id": "ii8lQkPJUsxb"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FuKq35rw-vm"
      },
      "source": [
        "Good!  We've developed a lot of great tools and bundled it together into a function.  Now we can apply it to live data coming from the camera."
      ],
      "id": "8FuKq35rw-vm"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxaSSWXaUsxb"
      },
      "source": [
        "We need a place to put the data.  A Numpy array is particularly well suited for this because it is a dense array.  If it is the proper shape, the data can be directly written there.  The numpy array must match the size of the incoming array exactly, or else weird things happen.  Note that this is a color camera, so each pixel has an RGB (Red, Green, Blue) value."
      ],
      "id": "jxaSSWXaUsxb"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zk8TSUxtw-vm"
      },
      "source": [
        "(nCols, nRows) = (160, 128)                                           # Choose the size of the camera collection\n",
        "imageData = np.zeros(shape=(nRows, nCols, 3), dtype='uint8')          # Create a location in RAM to put the data."
      ],
      "id": "zk8TSUxtw-vm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QiFQtY00w-vm"
      },
      "source": [
        "Next, we're going to create the camera object and then we're going to change some of its attributes."
      ],
      "id": "QiFQtY00w-vm"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88f0a7DUUsxc"
      },
      "source": [
        "try:\n",
        "    cam = PiCamera()\n",
        "except:\n",
        "    pass\n",
        "\n",
        "cam.resolution = (nCols, nRows)                                       # Set the camera resolution\n",
        "cam.framerate = 10                                                    # Framerate\n",
        "cam.rotation = 180                                                    # Rotation (depending on mounting, this could be either 0 or 180)"
      ],
      "id": "88f0a7DUUsxc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bwp_y4OHw-vt"
      },
      "source": [
        "A key thing that I want to make clear is that all the `cam.capture(imageData, 'rgb')` does is change the data in the numpy array `imageData`.  Additionally `imageData` is no different the other `(m,n,3)` Numpy arrays that we've been working on.  There is no magic here.\n",
        "\n",
        "This is very intentional.  Our previous image processing work and the image capture share the same *interface*."
      ],
      "id": "Bwp_y4OHw-vt"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GvmsaVP-w-vt"
      },
      "source": [
        "Let's use the camera to change the data in `imageData` and display it.  Execute the cell below as many times as you wish."
      ],
      "id": "GvmsaVP-w-vt"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxk8TlpRUsxc"
      },
      "source": [
        "cam.capture(imageData, 'rgb')\n",
        "displayArray(imageData)"
      ],
      "id": "pxk8TlpRUsxc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHGKiR_MUsxc"
      },
      "source": [
        "# Moving the Servos"
      ],
      "id": "iHGKiR_MUsxc"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIrFlqj6Usxd"
      },
      "source": [
        "from adafruit_servokit import ServoKit\n",
        "servoBoard = ServoKit(channels=16)"
      ],
      "id": "eIrFlqj6Usxd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w87PHC82Usxd"
      },
      "source": [
        "tiltServo = servoBoard.servo[0]  # Moves up and down.  The `0` here means the servo is plugged into the first slot on the control board.\n",
        "panServo = servoBoard.servo[1]   # Moves left and right.  The `1` here means the servo is plugged into the second slot on the control board."
      ],
      "id": "w87PHC82Usxd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OpWU3Ipsw-vv"
      },
      "source": [
        "The two servos both have ranges of [0, 180].  Play with this.  See what happens when you punch in different values."
      ],
      "id": "OpWU3Ipsw-vv"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQzoYu_Rw-vv"
      },
      "source": [
        "tiltServo.angle = 80.0\n",
        "panServo.angle = 100.0"
      ],
      "id": "oQzoYu_Rw-vv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3BkIHsow-vw"
      },
      "source": [
        "tiltServo.angle = 90.0\n",
        "panServo.angle = 90.0"
      ],
      "id": "m3BkIHsow-vw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GvqWVAMpw-vw"
      },
      "source": [
        "Can we make them move in a circle?"
      ],
      "id": "GvqWVAMpw-vw"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzBiHKp0Usxd"
      },
      "source": [
        "# PROBLEM\n",
        "for deg in range(360):\n",
        "    panServo.angle = 90 + 30*sin(deg*pi/180)       # FIXME\n",
        "    tiltServo.angle = 90 + 10*sin(deg*pi/180)      # FIXME\n",
        "    sleep(0.01)                             # Pauses for 0.01 seconds before moving onto next step.\n",
        "\n",
        "tiltServo.angle = 90.0                      # Return to center.\n",
        "panServo.angle = 90.0"
      ],
      "id": "pzBiHKp0Usxd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VSl_GujVw-vx"
      },
      "source": [
        "Just for fun, let's give it a bunch of small random deflections."
      ],
      "id": "VSl_GujVw-vx"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOU3YUHsw-vx"
      },
      "source": [
        "start = time()\n",
        "while(time() - start < 3):\n",
        "    panServo.angle = 0.1*np.random.normal() + panServo.angle\n",
        "    tiltServo.angle = 0.1*np.random.normal() + tiltServo.angle\n",
        "\n",
        "tiltServo.angle = 90.0                      # Return to center.\n",
        "panServo.angle = 90.0"
      ],
      "id": "jOU3YUHsw-vx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVioui1Sw-vy"
      },
      "source": [
        "# Putting it all together"
      ],
      "id": "FVioui1Sw-vy"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLxGV6aCw-vy"
      },
      "source": [
        "The goal of this last stage is to get the camera, image processing, and servos working together so that the camera follows an object around."
      ],
      "id": "xLxGV6aCw-vy"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5e8aGuQgw-vy"
      },
      "source": [
        "First we're going to begin by capturing an image and attempting to process it to find the target object.  Tweak the `targetColor`, and `threshold` until you feel like your code is doing a good job of selecting for the target object.\n",
        "\n",
        "As a general strategy, begin with a higher threshold and lower it as you dial in the target color."
      ],
      "id": "5e8aGuQgw-vy"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1YFXwCgw-vz"
      },
      "source": [
        "targetColor = [180, 20, 20]            # FIXME\n",
        "threshold = 0.15                       # FIXME\n",
        "cam.capture(imageData, 'rgb')\n",
        "displayArray(imageData)\n",
        "(rCoM, cCoM) = ImageTracker(imageData, targetColor=targetColor, threshold=threshold, dimFactor=0.25)\n",
        "print((rCoM, cCoM))"
      ],
      "id": "o1YFXwCgw-vz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJMj1pJbw-vz"
      },
      "source": [
        "Your target likely isn't at the center of the image.  We can use \"negative feedback\" to adjust the servos to point the camera at the target.  The term \"negative feedback\" means that we measure the error and we attempt to negate it by going the other way.  Our error is going to come in the form of how far the center-of-mass is from the center of the image.  We'll convert the error into a servo adjustment by way of a \"feedback coefficient.\"  The trick is adjust this term such that:\n",
        "* we're correcting in the right direction (the sign must feedback coeffient must be correct) or we make things worse!\n",
        "* it isn't too large (we could \"over-correct\" leading to oscilliatory behavior)\n",
        "* it isn't too small (we won't be able to keep up with the target.)\n",
        "\n",
        "Play with the feedback coefficients below until every time you execute the cell, it moves the camera to almost center the target."
      ],
      "id": "NJMj1pJbw-vz"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_uLXC-fw-v0"
      },
      "source": [
        "tiltServo.angle = 90.0                      # Return to center.\n",
        "panServo.angle = 90.0"
      ],
      "id": "B_uLXC-fw-v0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvIOGvz8w-v0"
      },
      "source": [
        "# PROBLEM\n",
        "def ObserveAndAdjust(targetColor, threshold):\n",
        "    (fbcCol, fbcRow) = (0.00, 0.00)  # FIXME\n",
        "    cam.capture(imageData, 'rgb')\n",
        "    (rCoM, cCoM) = ImageTracker(imageData, targetColor, threshold, dimFactor=0.25)\n",
        "    (rowCent, colCent) = (nRows/2, nCols/2)\n",
        "    errorPan = (cCoM - colCent)\n",
        "    errorTilt = (rCoM - rowCent)\n",
        "    panServo.angle += fbcCol*errorPan\n",
        "    tiltServo.angle += fbcRow*errorTilt\n",
        "\n",
        "ObserveAndAdjust(targetColor, threshold)"
      ],
      "id": "gvIOGvz8w-v0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4amip5fSw-v1"
      },
      "source": [
        "And now let's make it work continuously for 30 seconds.  \n",
        "\n",
        "Tip: It will look better if there are no cells under it.  Rather than hitting \"shift-enter\", press the play button to the left of the cell.  This won't automatically create another cell below."
      ],
      "id": "4amip5fSw-v1"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Lnql-Hcw-v1"
      },
      "source": [
        "start = time()\n",
        "while(time() - start < 30):\n",
        "    clear_output(wait=True)\n",
        "    ObserveAndAdjust(targetColor, threshold)"
      ],
      "id": "2Lnql-Hcw-v1",
      "execution_count": null,
      "outputs": []
    }
  ]
}